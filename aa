
C:\Users\l1313\.jenkins\workspace\Project-3>cd project-helm 
[Pipeline] bat

C:\Users\l1313\.jenkins\workspace\Project-3>helm install project-4 --dry-run  --debug --set image.repostitory=photop33/Project3,image.tag=${BUILD_NUMBER} project-helm 
install.go:173: [debug] Original chart version: ""
install.go:190: [debug] CHART PATH: C:\Users\l1313\.jenkins\workspace\Project-3\project-helm

NAME: project-4
LAST DEPLOYED: Sun Mar  7 17:10:47 2021
NAMESPACE: default
STATUS: pending-install
REVISION: 1
USER-SUPPLIED VALUES:
image:
  repostitory: photop33/Project3
  tag: ${BUILD_NUMBER}

COMPUTED VALUES:
affinity: {}
autoscaling:
  enabled: false
  maxReplicas: 100
  minReplicas: 1
  targetCPUUtilizationPercentage: 80
fullnameOverride: ""
image:
  pullPolicy: IfNotPresent
  repository: photop33/Project3
  repostitory: photop33/Project3
  tag: ${BUILD_NUMBER}
imagePullSecrets: []
ingress:
  annotations: {}
  enabled: false
  hosts:
  - host: chart-example.local
    paths: []
  tls: []
nameOverride: ""
nodeSelector: {}
podAnnotations: {}
podSecurityContext: {}
replicaCount: 5
resources: {}
securityContext: {}
service:
  port: 5500
  type: LoadBalancer
serviceAccount:
  annotations: {}
  create: true
  name: ""
tolerations: []

HOOKS:
---
# Source: lior/templates/tests/test-connection.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "project-4-lior-test-connection"
  labels:
    helm.sh/chart: lior-0.1.0
    app.kubernetes.io/name: lior
    app.kubernetes.io/instance: project-4
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": test
spec:
  containers:
    - name: wget
      image: busybox
      command: ['wget']
      args: ['project-4-lior:5500']
  restartPolicy: Never
MANIFEST:
---
# Source: lior/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: project-4-lior
  labels:
    helm.sh/chart: lior-0.1.0
    app.kubernetes.io/name: lior
    app.kubernetes.io/instance: project-4
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
---
# Source: lior/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: project-4-lior
  labels:
    helm.sh/chart: lior-0.1.0
    app.kubernetes.io/name: lior
    app.kubernetes.io/instance: project-4
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: LoadBalancer
  ports:
    - port: 5500
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: lior
    app.kubernetes.io/instance: project-4
---
# Source: lior/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: project-4-lior
  labels:
    helm.sh/chart: lior-0.1.0
    app.kubernetes.io/name: lior
    app.kubernetes.io/instance: project-4
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 5
  selector:
    matchLabels:
      app.kubernetes.io/name: lior
      app.kubernetes.io/instance: project-4
  template:
    metadata:
      labels:
        app.kubernetes.io/name: lior
        app.kubernetes.io/instance: project-4
    spec:
      serviceAccountName: project-4-lior
      securityContext:
        {}
      containers:
        - name: lior
          securityContext:
            {}
          image: "photop33/Project3:${BUILD_NUMBER}"
          imagePullPolicy: IfNotPresent
          ports:
            - name: http
              containerPort: 5500
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /
              port: http
          readinessProbe:
            httpGet:
              path: /
              port: http
          resources:
            {}

NOTES:
1. Get the application URL by running these commands:
     NOTE: It may take a few minutes for the LoadBalancer IP to be available.
           You can watch the status of by running 'kubectl get --namespace default svc -w project-4-lior'
  export SERVICE_IP=$(kubectl get svc --namespace default project-4-lior --template "{{ range (index .status.loadBalancer.ingress 0) }}{{.}}{{ end }}")
  echo http://$SERVICE_IP:5500
[Pipeline] bat

C:\Users\l1313\.jenkins\workspace\Project-3>helm repo update 
Hang tight while we grab the latest from your chart repositories...
...Successfully got an update from the "project" chart repository
...Successfully got an update from the "test" chart repository
...Successfully got an update from the "lior" chart repository
...Successfully got an update from the "traefik-mesh" chart repository
...Successfully got an update from the "jenkins" chart repository
...Successfully got an update from the "bitnami" chart repository
...Successfully got an update from the "stable" chart repository
Update Complete. ×’ï¿½Ë†Happy Helming!×’ï¿½Ë†
[Pipeline] bat

C:\Users\l1313\.jenkins\workspace\Project-3>helm list --all 
NAME      	NAMESPACE	REVISION	UPDATED                              	STATUS  	CHART       	APP VERSION
my-release	default  	1       	2021-03-06 22:49:42.0044355 +0200 IST	deployed	apache-8.3.2	2.4.46     
project   	default  	1       	2021-03-07 16:03:17.6745643 +0200 IST	deployed	lior-0.1.0  	1.16.0     
project-4 	default  	1       	2021-03-07 16:19:44.7139055 +0200 IST	deployed	lior-0.1.0  	1.16.0     
[Pipeline] }
[Pipeline] // script
[Pipeline] }
[Pipeline] // stage
[Pipeline] stage
[Pipeline] { (Deploy HELM)
[Pipeline] script
[Pipeline] {
[Pipeline] bat

C:\Users\l1313\.jenkins\workspace\Project-3>minikube start 
* minikube v1.17.1 on Microsoft Windows 10 Home 10.0.19041 Build 19041
* Using the docker driver based on existing profile
* Starting control plane node minikube in cluster minikube
* Updating the running docker "minikube" container ...
* Found network options:
  - NO_PROXY=192.168.99.100
  - no_proxy=192.168.99.100
* Preparing Kubernetes v1.20.2 on Docker 20.10.2 ...| WW[K[K
  - env NO_PROXY=192.168.99.100
* Verifying Kubernetes components...
* Enabled addons: storage-provisioner, dashboard, default-storageclass

! C:\Windows\system32\kubectl.exe is version 1.14.0, which may have incompatibilites with Kubernetes 1.20.2.
  - Want kubectl v1.20.2? Try 'minikube kubectl -- get pods -A'
* Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default
[Pipeline] bat

C:\Users\l1313\.jenkins\workspace\Project-3>cd project-helm 
[Pipeline] bat

C:\Users\l1313\.jenkins\workspace\Project-3>start/min minikube service project-4 --url  1>k8s_url.txt 
[Pipeline] bat

C:\Users\l1313\.jenkins\workspace\Project-3>type k8s_url.txt 
[Pipeline] bat

C:\Users\l1313\.jenkins\workspace\Project-3>echo succes Deploy HELM 
succes Deploy HELM
[Pipeline] }
[Pipeline] // script
[Pipeline] }
[Pipeline] // stage
[Pipeline] stage
[Pipeline] { (K8S_backend_testing.py)
[Pipeline] script
[Pipeline] {
[Pipeline] bat

C:\Users\l1313\.jenkins\workspace\Project-3>python3 K8S_backend_testing.py 
{'status': 'ok', 'user name': 'Daniel'}
[Pipeline] bat

C:\Users\l1313\.jenkins\workspace\Project-3>echo succes K8S_backend_testing.py 
succes K8S_backend_testing.py
[Pipeline] }
[Pipeline] // script
[Pipeline] }
[Pipeline] // stage
[Pipeline] stage
[Pipeline] { (extra-secret)
[Pipeline] script
[Pipeline] {
[Pipeline] bat

C:\Users\l1313\.jenkins\workspace\Project-3>start/min kubectl create secret generic project-4-secret --from-literal=usr=fFFGNbw0b0 --from-literal=pwd=66VHtH6ctH  
[Pipeline] bat

C:\Users\l1313\.jenkins\workspace\Project-3>kubectl get secrets  
NAME                               TYPE                                  DATA   AGE
default-token-k2bxp                kubernetes.io/service-account-token   3      12d
mysecret                           Opaque                                1      47h
project-4-lior-token-8wbsj         kubernetes.io/service-account-token   3      51m
project-4-secret                   Opaque                                2      7m54s
project-4-secret-db                Opaque                                2      16m
project-lior-token-hvv5d           kubernetes.io/service-account-token   3      67m
sample-db-secret                   Opaque                                2      2d3h
secret-basic-auth                  kubernetes.io/basic-auth              2      2d
secret-tiger-docker                kubernetes.io/dockerconfigjson        1      47h
sh.helm.release.v1.my-release.v1   helm.sh/release.v1                    1      18h
sh.helm.release.v1.project-4.v1    helm.sh/release.v1                    1      51m
sh.helm.release.v1.project.v1      helm.sh/release.v1                    1      67m
test-secret                        Opaque                                2      2d5h
[Pipeline] bat

C:\Users\l1313\.jenkins\workspace\Project-3>kubectl apply -f https://raw.githubusercontent.com/photop33/Project3/master/lior/templates/username.txt 
secret/mysecret configured
[Pipeline] bat

C:\Users\l1313\.jenkins\workspace\Project-3>kubectl get secret mysecret -o yaml 
apiVersion: v1
data:
  config.yaml: YXBpVXJsOiAiaHR0cHM6Ly9sb2NhbGhvc3Q6NTUwMC91c2VyLzEiCnVzZXJuYW1lOiBsaW9yCnBhc3N3b3JkOiAxMjM0Cg==
kind: Secret
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"v1","kind":"Secret","metadata":{"annotations":{},"name":"mysecret","namespace":"default"},"stringData":{"config.yaml":"apiUrl: \"https://localhost:5500/user/1\"\nusername: lior\npassword: 1234\n"},"type":"Opaque"}
  creationTimestamp: "2021-03-05T15:44:44Z"
  managedFields:
  - apiVersion: v1
    fieldsType: FieldsV1
    fieldsV1:
      f:data:
        .: {}
        f:config.yaml: {}
      f:metadata:
        f:annotations:
          .: {}
          f:kubectl.kubernetes.io/last-applied-configuration: {}
      f:type: {}
    manager: kubectl
    operation: Update
    time: "2021-03-05T15:44:44Z"
  name: mysecret
  namespace: default
  resourceVersion: "48984"
  uid: 07b50d67-a1a4-4a1d-93ff-e33ff5077ad7
type: Opaque
[Pipeline] bat

C:\Users\l1313\.jenkins\workspace\Project-3>kubectl get pod secret-envars-test-pod 
NAME                     READY   STATUS    RESTARTS   AGE
secret-envars-test-pod   1/1     Running   5          2d5h
[Pipeline] bat

C:\Users\l1313\.jenkins\workspace\Project-3>echo succes secret 
succes secret
[Pipeline] }
[Pipeline] // script
[Pipeline] }
[Pipeline] // stage
[Pipeline] stage
[Pipeline] { (extra config-map)
[Pipeline] script
[Pipeline] {
[Pipeline] bat

C:\Users\l1313\.jenkins\workspace\Project-3>echo next config-map  
next config-map 
[Pipeline] }
[Pipeline] // script
[Pipeline] }
[Pipeline] // stage
[Pipeline] stage
[Pipeline] { (extra-mysql)
[Pipeline] script
[Pipeline] {
[Pipeline] bat

C:\Users\l1313\.jenkins\workspace\Project-3>kubectl apply -f https://raw.githubusercontent.com/photop33/Project3/master/EXTRA-mysql/mysql-deployment2.yaml 
service/mysql unchanged
deployment.apps/mysql unchanged
[Pipeline] bat

C:\Users\l1313\.jenkins\workspace\Project-3>kubectl apply -f https://raw.githubusercontent.com/photop33/Project3/master/EXTRA-mysql/mysql-pv.yaml 
persistentvolume/mysql-pv-volume unchanged
persistentvolumeclaim/mysql-pv-claim unchanged
[Pipeline] bat

C:\Users\l1313\.jenkins\workspace\Project-3>kubectl describe deployment mysql 
Name:               mysql
Namespace:          default
CreationTimestamp:  Sun, 07 Mar 2021 14:38:13 +0200
Labels:             <none>
Annotations:        deployment.kubernetes.io/revision: 1
                    kubectl.kubernetes.io/last-applied-configuration:
                      {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"name":"mysql","namespace":"default"},"spec":{"selector":{"matchL...
Selector:           app=mysql
Replicas:           1 desired | 1 updated | 1 total | 0 available | 1 unavailable
StrategyType:       Recreate
MinReadySeconds:    0
Pod Template:
  Labels:  app=mysql
  Containers:
   mysql:
    Image:      mysql:5.6
    Port:       3306/TCP
    Host Port:  0/TCP
    Environment:
      MYSQL_ROOT_PASSWORD:  password
    Mounts:
      /var/lib/mysql from mysql-persistent-storage (rw)
  Volumes:
   mysql-persistent-storage:
    Type:       PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace)
    ClaimName:  mysql-pv-claim
    ReadOnly:   false
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      False   MinimumReplicasUnavailable
  Progressing    False   ProgressDeadlineExceeded
OldReplicaSets:  <none>
NewReplicaSet:   mysql-68579b78bb (1/1 replicas created)
[Pipeline] bat

C:\Users\l1313\.jenkins\workspace\Project-3>kubectl get pods -l app=mysql 
NAME                     READY   STATUS    RESTARTS   AGE
mysql-68579b78bb-mzggf   0/1     Pending   0          153m
[Pipeline] bat

C:\Users\l1313\.jenkins\workspace\Project-3>kubectl describe pvc mysql-pv-claim 
Name:          mysql-pv-claim
Namespace:     default
StorageClass:  manual
Status:        Pending
Volume:        
Labels:        <none>
Annotations:   kubectl.kubernetes.io/last-applied-configuration:
                 {"apiVersion":"v1","kind":"PersistentVolumeClaim","metadata":{"annotations":{},"name":"mysql-pv-claim","namespace":"default"},"spec":{"acc...
Finalizers:    [kubernetes.io/pvc-protection]
Capacity:      
Access Modes:  
VolumeMode:    Filesystem
Mounted By:    mysql-68579b78bb-mzggf
[Pipeline] bat

C:\Users\l1313\.jenkins\workspace\Project-3>start/min kubectl run -it --rm --image=mysql:5.6 --restart=Never mysql-client -- mysql -h mysql -ppassword 
[Pipeline] bat

C:\Users\l1313\.jenkins\workspace\Project-3>kubectl delete deployment,svc mysql 
deployment.apps "mysql" deleted
service "mysql" deleted
[Pipeline] bat

C:\Users\l1313\.jenkins\workspace\Project-3>kubectl delete pvc mysql-pv-claim 
persistentvolumeclaim "mysql-pv-claim" deleted
[Pipeline] bat

C:\Users\l1313\.jenkins\workspace\Project-3>kubectl delete pv mysql-pv-volume 
persistentvolume "mysql-pv-volume" deleted
[Pipeline] }
[Pipeline] // script
[Pipeline] }
[Pipeline] // stage
[Pipeline] stage
[Pipeline] { (clean_environemnt-3)
[Pipeline] script
[Pipeline] {
[Pipeline] bat

C:\Users\l1313\.jenkins\workspace\Project-3>start/min python3 clean_environemnt.py 
[Pipeline] bat

C:\Users\l1313\.jenkins\workspace\Project-3>echo success clean_environemnt-3 
success clean_environemnt-3
[Pipeline] }
[Pipeline] // script
[Pipeline] }
[Pipeline] // stage
[Pipeline] stage
[Pipeline] { (Declarative: Post Actions)
[Pipeline] bat

C:\Users\l1313\.jenkins\workspace\Project-3>docker rmi photop/project-3:598 
Untagged: photop/project-3:598
Untagged: photop/project-3@sha256:3345d8001f6544d18078e5c60d82df2bfa26584463f24cecb4c9adc7d42f74e4
[Pipeline] }
[Pipeline] // stage
[Pipeline] }
[Pipeline] // withEnv
[Pipeline] }
[Pipeline] // withEnv
[Pipeline] }
[Pipeline] // node
[Pipeline] End of Pipeline
